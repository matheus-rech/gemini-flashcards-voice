


import { GoogleGenAI, LiveServerMessage, Modality, FunctionDeclaration, Type, Blob as GenAI_Blob } from '@google/genai';
import { Card, Rating, VoiceName, INPUT_AUDIO_SAMPLE_RATE, OUTPUT_AUDIO_SAMPLE_RATE } from '../types';

// Audio decoding and encoding functions
function decode(base64: string): Uint8Array {
  const binaryString = atob(base64);
  const len = binaryString.length;
  const bytes = new Uint8Array(len);
  for (let i = 0; i < len; i++) {
    bytes[i] = binaryString.charCodeAt(i);
  }
  return bytes;
}

function encode(bytes: Uint8Array): string {
  let binary = '';
  const len = bytes.byteLength;
  for (let i = 0; i < len; i++) {
    binary += String.fromCharCode(bytes[i]);
  }
  return btoa(binary);
}

async function decodeAudioData(
  data: Uint8Array,
  ctx: AudioContext,
  sampleRate: number,
  numChannels: number,
): Promise<AudioBuffer> {
  const dataInt16 = new Int16Array(data.buffer);
  const frameCount = dataInt16.length / numChannels;
  const buffer = ctx.createBuffer(numChannels, frameCount, sampleRate);

  for (let channel = 0; channel < numChannels; channel++) {
    const channelData = buffer.getChannelData(channel);
    for (let i = 0; i < frameCount; i++) {
      channelData[i] = dataInt16[i * numChannels + channel] / 32768.0;
    }
  }
  return buffer;
}


// Gemini Service
let ai: GoogleGenAI;
const getAi = () => {
  if (!ai) {
    ai = new GoogleGenAI({ apiKey: process.env.API_KEY as string });
  }
  return ai;
};


// Function declarations for the model
const controlFunctions: FunctionDeclaration[] = [
  {
    name: 'startReview',
    description: "Starts a flashcard review session for a given deck.",
    parameters: {
      type: Type.OBJECT,
      properties: {
        deckName: { type: Type.STRING, description: 'The name of the deck to review, e.g., "World Capitals".' },
      },
      required: ['deckName'],
    },
  },
  {
    name: 'showAnswer',
    description: "Reveals the answer to the current flashcard.",
    parameters: { type: Type.OBJECT, properties: {} },
  },
  {
    name: 'rateCard',
    description: "Rates the user's recall of the current flashcard.",
    parameters: {
      type: Type.OBJECT,
      properties: {
        rating: { type: Type.STRING, enum: ['AGAIN', 'HARD', 'GOOD', 'EASY'] },
      },
      required: ['rating'],
    },
  },
   {
    name: 'startConversation',
    description: "Pauses the review to answer a user's question about the current flashcard's content.",
    parameters: {
      type: Type.OBJECT,
      properties: {
        query: { type: Type.STRING, description: 'The user\'s question, e.g., "why?" or "can you explain that?".' },
      },
      required: ['query'],
    },
  },
  {
    name: 'setStudyGoal',
    description: "Sets a study goal for the user.",
    parameters: {
      type: Type.OBJECT,
      properties: {
        target: { type: Type.NUMBER, description: 'The number of cards to review.' },
        goalType: { type: Type.STRING, enum: ['session', 'daily'], description: "The type of goal, either per 'session' or 'daily'." },
      },
      required: ['target', 'goalType'],
    },
  },
  {
    name: 'createDeck',
    description: "Creates a new, empty flashcard deck.",
    parameters: {
      type: Type.OBJECT,
      properties: {
        deckName: { type: Type.STRING, description: 'The name for the new deck.' },
      },
      required: ['deckName'],
    },
  },
  {
    name: 'generateDeckFromForm',
    description: "Creates a new deck with flashcards about a specific topic, generated by AI based on user-provided parameters.",
    parameters: {
      type: Type.OBJECT,
      properties: {
        topic: { type: Type.STRING, description: 'The topic for the new deck, e.g., "Photosynthesis".' },
        depth: { type: Type.STRING, enum: ['Beginner', 'Intermediate', 'Expert'], description: 'The desired complexity level of the cards.' },
        numberOfCards: { type: Type.NUMBER, description: 'The number of cards to generate.' },
      },
      required: ['topic', 'depth', 'numberOfCards'],
    },
  },
  {
    name: 'generateDeckFromDocument',
    description: "Analyzes text from an uploaded document and creates a deck of flashcards based on the key themes found.",
    parameters: {
      type: Type.OBJECT,
      properties: {
        deckName: { type: Type.STRING, description: 'The name for the new deck.' },
        documentText: { type: Type.STRING, description: 'The full text content of the user\'s document.' },
      },
      required: ['deckName', 'documentText'],
    },
  },
  {
    name: 'deleteDeck',
    description: "Deletes an existing flashcard deck and all its cards.",
    parameters: {
      type: Type.OBJECT,
      properties: {
        deckName: { type: Type.STRING, description: 'The name of the deck to delete.' },
      },
      required: ['deckName'],
    },
  },
  {
    name: 'listDecks',
    description: "Lists all available flashcard decks by name.",
    parameters: { type: Type.OBJECT, properties: {} },
  },
  {
    name: 'showDecks',
    description: "Displays a visual list of all available decks.",
    parameters: { type: Type.OBJECT, properties: {} },
  },
  {
    name: 'showImportView',
    description: "Shows the view for importing a deck from a file.",
    parameters: { type: Type.OBJECT, properties: {} },
  },
  {
    name: 'showSmartGenerationView',
    description: "Shows the view for advanced AI deck creation, either from a form or by analyzing a document.",
    parameters: { type: Type.OBJECT, properties: {} },
  },
  {
    name: 'showImageGenerationView',
    description: "Shows the view for generating an image from a text prompt.",
    parameters: { type: Type.OBJECT, properties: {} },
  },
  {
    name: 'showImageAnalysisView',
    description: "Shows the view for analyzing an uploaded image.",
    parameters: { type: Type.OBJECT, properties: {} },
  },
  {
    name: 'showTranscriptionView',
    description: "Shows the view for recording and transcribing audio.",
    parameters: { type: Type.OBJECT, properties: {} },
  },
  {
    name: 'showTextAnalysisView',
    description: "Shows the view for analyzing a piece of text.",
    parameters: { type: Type.OBJECT, properties: {} },
  },
  {
    name: 'generateImage',
    description: 'Generates an image based on a user\'s text description.',
    parameters: {
      type: Type.OBJECT,
      properties: {
        prompt: { type: Type.STRING, description: 'A detailed description of the image to generate.' },
      },
      required: ['prompt'],
    },
  },
  {
    name: 'createCard',
    description: "Creates a new flashcard in a specified deck.",
    parameters: {
      type: Type.OBJECT,
      properties: {
        deckName: { type: Type.STRING, description: 'The name of the deck to add the card to.' },
        question: { type: Type.STRING, description: 'The question for the new card.' },
        answer: { type: Type.STRING, description: 'The answer for the new card.' },
        explanation: { type: Type.STRING, description: 'An optional explanation for the card\'s answer.' },
      },
      required: ['deckName', 'question', 'answer'],
    },
  },
  {
    name: 'findCardToEdit',
    description: "Finds a specific flashcard in a deck to prepare for editing.",
    parameters: {
      type: Type.OBJECT,
      properties: {
        deckName: { type: Type.STRING, description: 'The name of the deck containing the card.' },
        questionQuery: { type: Type.STRING, description: 'Keywords from the question of the card to find.' },
      },
      required: ['deckName', 'questionQuery'],
    },
  },
  {
    name: 'updateCardContent',
    description: "Updates the question, answer, and/or explanation of the card currently selected for editing.",
    parameters: {
      type: Type.OBJECT,
      properties: {
        newQuestion: { type: Type.STRING, description: "The new text for the card's question." },
        newAnswer: { type: Type.STRING, description: "The new text for the card's answer." },
        newExplanation: { type: Type.STRING, description: "The new text for the card's explanation." },
      },
    },
  },
  {
    name: 'showCardStats',
    description: "Finds a specific card and displays its learning statistics.",
     parameters: {
      type: Type.OBJECT,
      properties: {
        deckName: { type: Type.STRING, description: 'The name of the deck containing the card.' },
        questionQuery: { type: Type.STRING, description: 'Keywords from the question of the card to find.' },
      },
      required: ['deckName', 'questionQuery'],
    },
  },
  {
    name: 'explainCard',
    description: "Generates and displays a detailed AI explanation for the card currently being viewed in the stats screen. Should be used when the user says 'explain this card' or similar while viewing stats.",
    parameters: { type: Type.OBJECT, properties: {} },
  },
  {
    name: 'generateCardsFromWeakness',
    description: 'Analyzes the user\'s performance in a deck, finds their weakest card, and generates new, related cards to help them improve.',
    parameters: {
      type: Type.OBJECT,
      properties: {
        deckName: { type: Type.STRING, description: 'The name of the deck to analyze and add cards to.' },
      },
      required: ['deckName'],
    },
  },
  {
    name: 'goBack',
    description: "Exits the current special view (like Deck List, Import View, or Stats View) and returns to the main interface.",
    parameters: { type: Type.OBJECT, properties: {} },
  },
];

const systemInstructionBase = `You are 'Echo', a friendly and intelligent flashcard assistant.
Your primary role is to guide the user through their study session using a spaced repetition system.
You MUST use the provided tools to control the app's functions. Do not answer flashcard questions yourself unless the user asks for an explanation.

Core Workflow:
1. When the user says 'start review', call startReview.
2. After a question is shown, wait for 'show answer', then call showAnswer.
3. After the answer is shown, wait for a rating ('again', 'hard', 'good', 'easy'), then call rateCard.
4. The app proceeds to the next card.

Advanced Capabilities:
- Deck Management: You can create, delete, and list decks (createDeck, deleteDeck, listDecks, showDecks).
- AI Deck Creation: You can create a full deck of cards on any topic for the user. Use the advanced 'Smart Generation' view (showSmartGenerationView) which allows creation from a form (generateDeckFromForm) or from a document (generateDeckFromDocument). Guide the user toward this feature for powerful content creation.
- Adaptive Learning: You can analyze a user's weak points in a deck and generate new cards to help them improve using generateCardsFromWeakness.
- Import & Upload: The user can import decks from a CSV file (showImportView). The 'Smart Generation' view is the primary way to use uploaded text.
- Image Generation: You can generate an image from a text prompt. Use showImageGenerationView to open the screen, or generate directly with generateImage.
- Image Analysis: You can analyze an image the user uploads. Use showImageAnalysisView to open the screen.
- Text Analysis: You can analyze any piece of text for the user. Use showTextAnalysisView to open the screen.
- Audio Transcription: You can transcribe audio for the user. Use showTranscriptionView to open the screen.
- Card Management: You can create cards manually (createCard) and edit them (findCardToEdit, then updateCardContent). Cards can include questions, answers, and explanations.
- Card Statistics: You can show the user their learning progress on a specific card (showCardStats). While viewing stats, you can provide an AI explanation for that card (explainCard).
- Navigation: Use goBack to exit from special views like the deck list or import screen.
- Study Goals: The user can set study goals using setStudyGoal.

General Interaction:
Start by introducing yourself and telling the user to say "Start review for [deck name]" to begin. You can also mention other features like Smart Deck Creation.`;

const conversationalInstruction = `
Conversational Learning:
- If the user interrupts the review to ask a question about the current card's content (e.g., "why?", "explain that", "tell me more"), you MUST use the 'startConversation' tool. Pass their question as the 'query' parameter.`;


export const geminiService = {
  connectLive: (
    onMessage: (message: LiveServerMessage) => void,
    onError: (e: ErrorEvent) => void,
    onClose: (e: CloseEvent) => void,
    voiceName: VoiceName,
    isConversationalModeEnabled: boolean
  ) => {
    const ai = getAi();

    const systemInstruction = isConversationalModeEnabled
      ? systemInstructionBase + conversationalInstruction
      : systemInstructionBase;

    const sessionPromise = ai.live.connect({
      model: 'gemini-2.5-flash-native-audio-preview-09-2025',
      callbacks: {
        onopen: async () => {
          const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
          const inputAudioContext = new (window.AudioContext || (window as any).webkitAudioContext)({ sampleRate: INPUT_AUDIO_SAMPLE_RATE });
          const source = inputAudioContext.createMediaStreamSource(stream);
          const scriptProcessor = inputAudioContext.createScriptProcessor(4096, 1, 1);
          scriptProcessor.onaudioprocess = (audioProcessingEvent) => {
            const inputData = audioProcessingEvent.inputBuffer.getChannelData(0);
            const l = inputData.length;
            const int16 = new Int16Array(l);
            for (let i = 0; i < l; i++) {
              int16[i] = inputData[i] * 32768;
            }
            const pcmBlob: GenAI_Blob = {
              data: encode(new Uint8Array(int16.buffer)),
              mimeType: `audio/pcm;rate=${INPUT_AUDIO_SAMPLE_RATE}`,
            };
            sessionPromise.then((session) => {
              session.sendRealtimeInput({ media: pcmBlob });
            });
          };
          source.connect(scriptProcessor);
          scriptProcessor.connect(inputAudioContext.destination);
        },
        onmessage: onMessage,
        onerror: onError,
        onclose: onClose,
      },
      config: {
        responseModalities: [Modality.AUDIO],
        speechConfig: { voiceConfig: { prebuiltVoiceConfig: { voiceName: voiceName } } },
        tools: [{ functionDeclarations: controlFunctions }],
        inputAudioTranscription: {},
        systemInstruction: systemInstruction,
      },
    });
    return sessionPromise;
  },

  /**
   * Generates Text-to-Speech audio using the dedicated TTS model.
   * This is a non-streaming, unary call that returns a complete audio file.
   * As per investigation, while the Live API provides streaming audio output for conversations, 
   * this dedicated model is the correct and optimized approach for generating high-quality audio 
   * from a static text prompt (like reading a flashcard), ensuring the clearest output.
   * The audio is returned as a base64 encoded string.
   */
  generateTts: async (text: string, voiceName: VoiceName): Promise<string> => {
    try {
      const ai = getAi();
      const response = await ai.models.generateContent({
        model: 'gemini-2.5-flash-preview-tts',
        contents: [{ parts: [{ text: text }] }],
        config: {
          responseModalities: [Modality.AUDIO],
          speechConfig: { voiceConfig: { prebuiltVoiceConfig: { voiceName: voiceName } } },
        },
      });
      return response.candidates?.[0]?.content?.parts?.[0]?.inlineData?.data ?? '';
    } catch (error) {
      console.error("TTS generation failed:", error);
      return '';
    }
  },
  
  getExplanation: async (card: Card, query: string): Promise<string> => {
    try {
      const ai = getAi();
      const prompt = `A user is studying a flashcard and needs an explanation.
      Flashcard Question: "${card.question}"
      Flashcard Answer: "${card.answer}"
      ${card.explanation ? `Existing Explanation: "${card.explanation}"` : ''}
      User's Query: "${query}"
      
      Please provide a clear and helpful explanation that addresses the user's query based on the flashcard content. Be conversational and encouraging.`;
      
      const response = await ai.models.generateContent({
        model: 'gemini-2.5-pro',
        contents: [{ parts: [{ text: prompt }] }],
        config: {
            thinkingConfig: { thinkingBudget: 32768 },
        }
      });
      
      return response.text;
    } catch (error) {
        console.error("Explanation generation failed:", error);
        return "Sorry, I had trouble thinking of an explanation for that. Let's get back to the review.";
    }
  },

  getCardExplanation: async (card: Card): Promise<string> => {
    try {
      const ai = getAi();
      const prompt = `A user is viewing statistics for a flashcard and has requested an explanation.
      Flashcard Question: "${card.question}"
      Flashcard Answer: "${card.answer}"
      
      Please provide a clear, comprehensive, and helpful explanation that connects the question to the answer. 
      Break down complex topics if necessary. Be conversational and encouraging.`;
      
      const response = await ai.models.generateContent({
        model: 'gemini-2.5-pro',
        contents: [{ parts: [{ text: prompt }] }],
        config: {
            thinkingConfig: { thinkingBudget: 32768 },
        }
      });
      
      return response.text;
    } catch (error) {
        console.error("Card explanation generation failed:", error);
        return "Sorry, I had trouble generating an explanation for this card. Please try again.";
    }
  },

  generateDeckFromForm: async (topic: string, depth: string, numberOfCards: number): Promise<{question: string, answer: string, explanation?: string}[]> => {
    try {
      const ai = getAi();
      const prompt = `Generate ${numberOfCards} flashcards for the topic "${topic}" at a "${depth}" level of complexity. Each card must have a clear question, a concise answer, and a brief, helpful explanation for context.`;

      const response = await ai.models.generateContent({
        model: 'gemini-2.5-pro',
        contents: [{ parts: [{ text: prompt }] }],
        config: {
          responseMimeType: 'application/json',
          responseSchema: {
            type: Type.ARRAY,
            items: {
              type: Type.OBJECT,
              properties: {
                question: { type: Type.STRING, description: "The question for the flashcard." },
                answer: { type: Type.STRING, description: "The answer to the question." },
                explanation: { type: Type.STRING, description: "A brief explanation for additional context." },
              },
              required: ['question', 'answer', 'explanation'],
            },
          },
          thinkingConfig: { thinkingBudget: 32768 },
        },
      });

      const jsonText = response.text.trim();
      const deckData = JSON.parse(jsonText);
      return deckData;
    } catch (error) {
      console.error("AI Deck generation from form failed:", error);
      return []; 
    }
  },

   generateDeckFromDocument: async (deckName: string, documentText: string): Promise<{question: string, answer: string, explanation?: string}[]> => {
    try {
      const ai = getAi();
      const prompt = `Analyze the following document text and generate a comprehensive deck of flashcards named "${deckName}". Identify the key concepts, definitions, and facts. For each, create a card with a clear question, a concise answer, and a brief, helpful explanation.

      Document Text:
      ---
      ${documentText}
      ---
      `;

      const response = await ai.models.generateContent({
        model: 'gemini-2.5-pro',
        contents: [{ parts: [{ text: prompt }] }],
        config: {
          responseMimeType: 'application/json',
          responseSchema: {
            type: Type.ARRAY,
            items: {
              type: Type.OBJECT,
              properties: {
                question: { type: Type.STRING, description: "The question for the flashcard." },
                answer: { type: Type.STRING, description: "The answer to the question." },
                explanation: { type: Type.STRING, description: "A brief explanation for additional context." },
              },
              required: ['question', 'answer', 'explanation'],
            },
          },
          thinkingConfig: { thinkingBudget: 32768 },
        },
      });

      const jsonText = response.text.trim();
      return JSON.parse(jsonText);
    } catch (error) {
      console.error("AI Deck generation from document failed:", error);
      return []; 
    }
  },

  generateTargetedCards: async (topicCard: Card, context: string, numberOfCards: number): Promise<{question: string, answer: string, explanation?: string}[]> => {
    try {
      const ai = getAi();
      const prompt = `A user is struggling with the following flashcard:
      - Question: "${topicCard.question}"
      - Answer: "${topicCard.answer}"

      Here is some relevant context from a knowledge base:
      ---
      ${context}
      ---
      
      Based on this context, generate ${numberOfCards} new, related flashcards to help the user better understand the topic. The new cards should not be identical to the original card. They should explore related concepts, provide different examples, or break down the topic in a new way. Each new card must include a question, answer, and a brief explanation.`;

      const response = await ai.models.generateContent({
        model: 'gemini-2.5-pro',
        contents: [{ parts: [{ text: prompt }] }],
        config: {
          responseMimeType: 'application/json',
          responseSchema: {
            type: Type.ARRAY,
            items: {
              type: Type.OBJECT,
              properties: {
                question: { type: Type.STRING, description: "The question for the flashcard." },
                answer: { type: Type.STRING, description: "The answer to the question." },
                explanation: { type: Type.STRING, description: "A brief explanation for additional context." },
              },
              required: ['question', 'answer', 'explanation'],
            },
          },
          thinkingConfig: { thinkingBudget: 32768 },
        },
      });
      const jsonText = response.text.trim();
      return JSON.parse(jsonText);

    } catch (error) {
      console.error("Targeted card generation failed:", error);
      return [];
    }
  },

  generateImage: async (prompt: string): Promise<string | null> => {
    try {
      const ai = getAi();
      const response = await ai.models.generateImages({
        model: 'imagen-4.0-generate-001',
        prompt: prompt,
        config: {
          numberOfImages: 1,
          outputMimeType: 'image/jpeg',
          aspectRatio: '1:1',
        },
      });

      const base64ImageBytes = response.generatedImages[0].image.imageBytes;
      return `data:image/jpeg;base64,${base64ImageBytes}`;
    } catch (error) {
      console.error("Image generation failed:", error);
      return null;
    }
  },

  analyzeImage: async (prompt: string, imageBase64: string, mimeType: string): Promise<string> => {
    try {
      const ai = getAi();
      const imagePart = {
        inlineData: {
          mimeType: mimeType,
          data: imageBase64,
        },
      };
      const textPart = { text: prompt };

      const response = await ai.models.generateContent({
        model: 'gemini-2.5-flash',
        contents: { parts: [imagePart, textPart] },
      });
      
      return response.text;
    } catch (error) {
      console.error("Image analysis failed:", error);
      return "Sorry, I had trouble analyzing that image.";
    }
  },

  transcribeAudio: async (audioBase64: string, mimeType: string): Promise<string> => {
    try {
      const ai = getAi();
      const audioPart = {
        inlineData: {
          mimeType: mimeType,
          data: audioBase64,
        },
      };
      const textPart = { text: "Transcribe this audio precisely." };

      const response = await ai.models.generateContent({
        model: 'gemini-2.5-flash',
        contents: { parts: [audioPart, textPart] },
      });
      
      return response.text;
    } catch (error) {
      console.error("Audio transcription failed:", error);
      return "Sorry, I had trouble transcribing that audio.";
    }
  },

  analyzeText: async (textToAnalyze: string, prompt: string, complexity: 'simple' | 'complex' = 'simple'): Promise<string> => {
    try {
      const ai = getAi();
      const model = complexity === 'complex' ? 'gemini-2.5-pro' : 'gemini-2.5-flash';
      const config = complexity === 'complex' ? { thinkingConfig: { thinkingBudget: 32768 } } : {};
      
      const fullPrompt = `Analyze the following text based on the user's request.
      
      Text to Analyze:
      ---
      ${textToAnalyze}
      ---
      
      User's Request: "${prompt}"`;

      const response = await ai.models.generateContent({
        model,
        contents: [{ parts: [{ text: fullPrompt }] }],
        config,
      });
      
      return response.text;
    } catch (error) {
      console.error("Text analysis failed:", error);
      return "Sorry, I had trouble analyzing that text.";
    }
  },

  decodeAudio: decode,
  decodeAudioData,
};